{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17ab9f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kaifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re, regex\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import make_scorer, classification_report, precision_score, recall_score, f1_score, accuracy_score, jaccard_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16cff1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "val_df   = pd.read_csv(\"../data/val.csv\")\n",
    "test_df  = pd.read_csv(\"../data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50aebfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_EMOTIONS = ['joy','sadness','anger','fear','surprise','disgust','neutral','love']\n",
    "X_train, y_train = train_df[\"text\"], train_df[TARGET_EMOTIONS]\n",
    "X_val, y_val     = val_df[\"text\"], val_df[TARGET_EMOTIONS]\n",
    "X_test, y_test   = test_df[\"text\"], test_df[TARGET_EMOTIONS]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90fa067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    }
   ],
   "source": [
    "def preprocess(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text.lower())\n",
    "    return word_tokenize(text)\n",
    "\n",
    "train_tokens = X_train.apply(preprocess)\n",
    "val_tokens   = X_val.apply(preprocess)\n",
    "test_tokens  = X_test.apply(preprocess)\n",
    "\n",
    "w2v_model = Word2Vec(\n",
    "    sentences=train_tokens,\n",
    "    vector_size=500,  # embedding dimension\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4,\n",
    "    sg=1,             \n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ab5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Word2Vec trained — vocabulary size: 11334\n"
     ]
    }
   ],
   "source": [
    "print(\"✅ Word2Vec trained — vocabulary size:\", len(w2v_model.wv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d5a827c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31749, 500), (6803, 500), (6804, 500))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_vector(tokens, model, dim=300):\n",
    "    vec = np.zeros(dim)\n",
    "    count = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vec += model.wv[word]\n",
    "            count += 1\n",
    "            \n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec\n",
    "\n",
    "X_train_vec = np.vstack(train_tokens.apply(lambda x: sentence_vector(x, w2v_model, dim=500)))\n",
    "X_val_vec   = np.vstack(val_tokens.apply(lambda x: sentence_vector(x, w2v_model, dim=500)))\n",
    "X_test_vec  = np.vstack(test_tokens.apply(lambda x: sentence_vector(x, w2v_model, dim=500)))\n",
    "X_train_vec.shape, X_val_vec.shape, X_test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "716847dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X, y, dataset_name=\"Dataset\", get_classification_report=False):\n",
    "    y_pred = clf.predict(X)\n",
    "\n",
    "    print(f\"{dataset_name} Report:\")\n",
    "    if get_classification_report:\n",
    "        print(\"\\nValidation Classification Report:\")\n",
    "        print(classification_report(y, y_pred, target_names=TARGET_EMOTIONS, digits=3))\n",
    "\n",
    "    micro_p = precision_score(y, y_pred, average=\"micro\")\n",
    "    micro_r = recall_score(y, y_pred, average=\"micro\")\n",
    "    micro_f1 = f1_score(y, y_pred, average=\"micro\")\n",
    "\n",
    "    macro_p = precision_score(y, y_pred, average=\"macro\")\n",
    "    macro_r = recall_score(y, y_pred, average=\"macro\")\n",
    "    macro_f1 = f1_score(y, y_pred, average=\"macro\")\n",
    "\n",
    "    print(f\"Micro Precision: {micro_p:.3f}, Micro Recall: {micro_r:.3f}, Micro F1: {micro_f1:.3f}\")\n",
    "    print(f\"Macro Precision: {macro_p:.3f}, Macro Recall: {macro_r:.3f}, Macro F1: {macro_f1:.3f}\")\n",
    "\n",
    "    subset_acc = accuracy_score(y, y_pred)\n",
    "    jaccard_acc = jaccard_score(y, y_pred, average=\"samples\")\n",
    "\n",
    "    print(f\"Subset Accuracy (Exact Match): {subset_acc:.3f}\")\n",
    "    print(f\"Jaccard Accuracy (Sample-based): {jaccard_acc:.3f}\")\n",
    "    return {\n",
    "        \"micro_precision\": micro_p,\n",
    "        \"micro_recall\": micro_r,\n",
    "        \"micro_f1\": micro_f1,\n",
    "        \"macro_precision\": macro_p,\n",
    "        \"macro_recall\": macro_r,\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"subset_accuracy\": subset_acc,\n",
    "        \"jaccard_accuracy\": jaccard_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220a75c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eff2bca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5b8e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clf = LogisticRegression()\n",
    "clf = OneVsRestClassifier(base_clf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edb7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__solver\": ['liblinear', 'saga'],\n",
    "    \"estimator__C\": [0.5, 1.0, 2.0],\n",
    "    \"estimator__penalty\": ['l1', 'l2'],\n",
    "    \"estimator__class_weight\": [None, 'balanced'],\n",
    "    \"estimator__max_iter\": [500, 1000, 1500]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average='micro')\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=2\n",
    ")\n",
    "\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Logistic Regression (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.DataFrame([result])\n",
    "result_df.to_csv('../results/best_model_test_results_w2v.csv', index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_LR_results_w2v.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d28a4",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed91ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385c1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(GaussianNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b528055",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n    estimator.fit(X, y, **fit_params)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 889, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 15\u001b[0m\n\u001b[0;32m      6\u001b[0m f1_micro \u001b[38;5;241m=\u001b[39m make_scorer(f1_score, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m      8\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf,\n\u001b[0;32m      9\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[1;32m---> 15\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGrid Search Complete.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1001\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    995\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    996\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    997\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    998\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    999\u001b[0m     )\n\u001b[1;32m-> 1001\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1003\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1007\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:517\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    511\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    520\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    521\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 24 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\multiclass.py\", line 376, in fit\n    self.estimators_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose)(\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 77, in __call__\n    return super().__call__(iterable_with_config)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\joblib\\parallel.py\", line 1986, in __call__\n    return output if self.return_generator else list(output)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\joblib\\parallel.py\", line 1914, in _get_sequential_output\n    res = func(*args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 139, in __call__\n    return self.function(*args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\multiclass.py\", line 96, in _fit_binary\n    estimator.fit(X, y, **fit_params)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 762, in fit\n    self._count(X, Y)\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\naive_bayes.py\", line 889, in _count\n    check_non_negative(X, \"MultinomialNB (input X)\")\n  File \"c:\\Users\\kaifa\\anaconda3\\envs\\inpaint\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 1827, in check_non_negative\n    raise ValueError(f\"Negative values in data passed to {whom}.\")\nValueError: Negative values in data passed to MultinomialNB (input X).\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    # \"estimator\": [GaussianNB()],  \n",
    "    \"estimator__alpha\": [0.1, 0.5, 1.0, 2.0],        \n",
    "    \"estimator__fit_prior\": [True, False]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average='micro')\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Gaussian Naive Bayes (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv') if os.path.exists('../results/best_model_test_results_w2v.csv') else pd.DataFrame()\n",
    "result_df = pd.concat([result_df, pd.DataFrame([result])], ignore_index=True)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_GNB_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747129ec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6ca88a0",
   "metadata": {},
   "source": [
    "### Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b5c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae89f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(LinearSVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"estimator__class_weight\": [None, \"balanced\"],\n",
    "    \"estimator__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"estimator__max_iter\": [1000, 1500]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average=\"micro\")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Starting Grid Search for Linear SVM...\")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Linear SVM (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv')\n",
    "result_df = pd.concat([result_df, pd.DataFrame([result])], ignore_index=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_Linear_SVC_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "425da204",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8defaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__C\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"estimator__class_weight\": [None, \"balanced\"],\n",
    "    \"estimator__loss\": [\"hinge\", \"squared_hinge\"],\n",
    "    \"estimator__max_iter\": [1000, 1500]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average=\"micro\")\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Starting Grid Search for Linear SVM...\")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Linear SVM (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv')\n",
    "result_df = result_df.append(result, ignore_index=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_NB_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9948b63",
   "metadata": {},
   "source": [
    "### Ridge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d024e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3aab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(RidgeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164e681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search for Ridge Classifier...\n",
      "\n",
      "Grid Search Complete.\n",
      "Best Params: {'estimator__alpha': 1.0, 'estimator__solver': 'lsqr', 'estimator__tol': 0.001}\n",
      "Best Cross-Validated Micro-F1: 0.6747333570269541\n",
      "Validation Set Report:\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy      0.767     0.334     0.465       866\n",
      "     sadness      0.760     0.325     0.455       662\n",
      "       anger      0.679     0.289     0.405       866\n",
      "        fear      0.790     0.319     0.455       307\n",
      "    surprise      0.778     0.298     0.431       554\n",
      "     disgust      0.673     0.223     0.335       600\n",
      "     neutral      0.804     0.890     0.845      4752\n",
      "        love      0.862     0.555     0.676       641\n",
      "\n",
      "   micro avg      0.793     0.620     0.696      9248\n",
      "   macro avg      0.764     0.404     0.508      9248\n",
      "weighted avg      0.779     0.620     0.658      9248\n",
      " samples avg      0.766     0.688     0.703      9248\n",
      "\n",
      "Micro Precision: 0.793, Micro Recall: 0.620, Micro F1: 0.696\n",
      "Macro Precision: 0.764, Macro Recall: 0.404, Macro F1: 0.508\n",
      "Subset Accuracy (Exact Match): 0.526\n",
      "Jaccard Accuracy (Sample-based): 0.657\n",
      "Test Set Report:\n",
      "Micro Precision: 0.783, Micro Recall: 0.610, Micro F1: 0.686\n",
      "Macro Precision: 0.755, Macro Recall: 0.390, Macro F1: 0.494\n",
      "Subset Accuracy (Exact Match): 0.518\n",
      "Jaccard Accuracy (Sample-based): 0.649\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"estimator__alpha\": [0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    \"estimator__tol\": [1e-3, 1e-4],\n",
    "    \"estimator__solver\": [\"auto\", \"sparse_cg\", \"lsqr\"]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average=\"micro\")\n",
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"Starting Grid Search for Ridge Classifier...\")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Ridge Classifier (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv')\n",
    "result_df = pd.concat([result_df, pd.DataFrame([result])], ignore_index=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_Ridge_Classifier_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaef49d0",
   "metadata": {},
   "source": [
    "### SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c9283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c675c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = OneVsRestClassifier(SGDClassifier(random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e5c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"estimator__loss\": [\"hinge\", \"log_loss\", \"modified_huber\"],\n",
    "    \"estimator__penalty\": [\"l2\", \"l1\", \"elasticnet\"],\n",
    "    \"estimator__alpha\": [1e-5, 1e-4, 1e-3],\n",
    "    \"estimator__max_iter\": [1000, 1500],\n",
    "    \"estimator__tol\": [1e-3, 1e-4],\n",
    "    \"estimator__class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "f1_micro = make_scorer(f1_score, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03206ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search for SGD Classifier...\n",
      "\n",
      "Grid Search Complete.\n",
      "Best Params: {'estimator__alpha': 0.0001, 'estimator__class_weight': None, 'estimator__loss': 'hinge', 'estimator__max_iter': 1000, 'estimator__penalty': 'l1', 'estimator__tol': 0.0001}\n",
      "Best Cross-Validated Micro-F1: 0.7034871849957444\n",
      "Validation Set Report:\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy      0.825     0.311     0.451       866\n",
      "     sadness      0.795     0.293     0.428       662\n",
      "       anger      0.713     0.269     0.391       866\n",
      "        fear      0.777     0.375     0.505       307\n",
      "    surprise      0.811     0.318     0.457       554\n",
      "     disgust      0.702     0.220     0.335       600\n",
      "     neutral      0.805     0.916     0.857      4752\n",
      "        love      0.870     0.658     0.750       641\n",
      "\n",
      "   micro avg      0.803     0.637     0.711      9248\n",
      "   macro avg      0.787     0.420     0.522      9248\n",
      "weighted avg      0.795     0.637     0.668      9248\n",
      " samples avg      0.809     0.710     0.734      9248\n",
      "\n",
      "Micro Precision: 0.803, Micro Recall: 0.637, Micro F1: 0.711\n",
      "Macro Precision: 0.787, Macro Recall: 0.420, Macro F1: 0.522\n",
      "Subset Accuracy (Exact Match): 0.551\n",
      "Jaccard Accuracy (Sample-based): 0.687\n",
      "Test Set Report:\n",
      "Micro Precision: 0.796, Micro Recall: 0.625, Micro F1: 0.700\n",
      "Macro Precision: 0.790, Macro Recall: 0.401, Macro F1: 0.506\n",
      "Subset Accuracy (Exact Match): 0.545\n",
      "Jaccard Accuracy (Sample-based): 0.676\n"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(\n",
    "    estimator=clf,\n",
    "    param_grid=param_grid,\n",
    "    scoring=f1_micro,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "print(\"Starting Grid Search for SGD Classifier...\")\n",
    "grid.fit(X_train_vec, y_train)\n",
    "print(\"\\nGrid Search Complete.\")\n",
    "print(\"Best Params:\", grid.best_params_)\n",
    "print(\"Best Cross-Validated Micro-F1:\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'SGD Classifier (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv')\n",
    "result_df = pd.concat([result_df, pd.DataFrame([result])], ignore_index=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)\n",
    "\n",
    "results = pd.DataFrame(grid.cv_results_)\n",
    "os.makedirs(\"../results\", exist_ok=True)\n",
    "results.to_csv(\"../results/gridsearch_SGD_Classifier_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d45d02",
   "metadata": {},
   "source": [
    "### Ensemble (Voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af3a332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edc860",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=2.0, solver='liblinear', max_iter=1000)\n",
    "nb = GaussianNB(alpha=0.5)\n",
    "lr2 = LogisticRegression(C=1.0, solver='liblinear', max_iter=1000)\n",
    "\n",
    "voting_clf = OneVsRestClassifier(\n",
    "    VotingClassifier(\n",
    "        estimators=[('lr', lr), ('nb', nb), ('lr2', lr2), ('svc', LinearSVC(C=0.5, max_iter=1500))],\n",
    "        voting='soft'\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30083f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Report:\n",
      "\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         joy      0.833     0.237     0.369       866\n",
      "     sadness      0.837     0.193     0.314       662\n",
      "       anger      0.832     0.194     0.315       866\n",
      "        fear      0.717     0.107     0.187       307\n",
      "    surprise      0.811     0.155     0.261       554\n",
      "     disgust      0.753     0.112     0.194       600\n",
      "     neutral      0.785     0.936     0.854      4752\n",
      "        love      0.906     0.538     0.675       641\n",
      "\n",
      "   micro avg      0.796     0.593     0.679      9248\n",
      "   macro avg      0.809     0.309     0.396      9248\n",
      "weighted avg      0.803     0.593     0.607      9248\n",
      " samples avg      0.767     0.665     0.692      9248\n",
      "\n",
      "Micro Precision: 0.796, Micro Recall: 0.593, Micro F1: 0.679\n",
      "Macro Precision: 0.809, Macro Recall: 0.309, Macro F1: 0.396\n",
      "Subset Accuracy (Exact Match): 0.525\n",
      "Jaccard Accuracy (Sample-based): 0.648\n",
      "Test Set Report:\n",
      "Micro Precision: 0.790, Micro Recall: 0.587, Micro F1: 0.674\n",
      "Macro Precision: 0.838, Macro Recall: 0.308, Macro F1: 0.397\n",
      "Subset Accuracy (Exact Match): 0.523\n",
      "Jaccard Accuracy (Sample-based): 0.644\n"
     ]
    }
   ],
   "source": [
    "voting_clf.fit(X_train_vec, y_train)\n",
    "best_model = voting_clf\n",
    "evaluate_model(best_model, X_val_vec, y_val, dataset_name=\"Validation Set\", get_classification_report=True)\n",
    "best_result = evaluate_model(best_model, X_test_vec, y_test, dataset_name=\"Test Set\")\n",
    "result = {'Model' : 'Voting (lr, nb, svm) (One-vs-Rest)'}\n",
    "\n",
    "result.update(best_result)\n",
    "result_df = pd.read_csv('../results/best_model_test_results_w2v.csv')\n",
    "result_df = pd.concat([result_df, pd.DataFrame([result])], ignore_index=True)\n",
    "result_df.to_csv(\"../results/best_model_test_results_w2v.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ee420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inpaint_gpu_ipynb",
   "language": "python",
   "name": "inpaint"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
